{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics - Hooks in PyTorch\n",
    "By [Akshaj Verma](https://akshajverma.com/)\n",
    "\n",
    "This notebook takes you through the implementation of hooks in PyTorch through an example of multiclass classification using feedforward networks on the IRIS dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Enable GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://open.spotify.com/track/7CmU7JYRrW3AVko82AnZgo?si=NlwFNSjtQ_i4bS9aIw3BNg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(69)\n",
    "np.random.seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're using cuda? True\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "print(\"We're using cuda?\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/tabular/classification/iris.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7faae45da4e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'Species', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do that, let's create a dictionary called `class2idx` and use the `.replace()` method from the Pandas library to change it. Let's also create a reverse mapping called `idx2class` which converts the IDs back to their original classes.\n",
    "\n",
    "\n",
    "To create the reverse mapping, we create a dictionary comprehension and simply reverse the key and value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch supports labels starting from 0. That is [0, n]. We need to remap our labels to start from 0.\n",
    "\n",
    "class2idx = {\n",
    "    \"Iris-setosa\": 0,\n",
    "    \"Iris-versicolor\": 1,\n",
    "    \"Iris-virginica\": 2\n",
    "    \n",
    "}\n",
    "\n",
    "idx2class = {v: k for k, v in class2idx.items()}\n",
    "\n",
    "df['Species'].replace(class2idx, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to split our data into train, validation, and test sets, we need to separate out our inputs and outputs. \n",
    "\n",
    "\n",
    "Input X is all but the last column. Output y is the last column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 0:-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Custom Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First up, let's define a custom dataset. This dataset will be used by the dataloader to pass our data into our model.   \n",
    "We initialize our dataset by passing `X` and `y` as inputs. Make sure `X` is a `float` while `y` is `long`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "train_dataset = ClassifierDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
    "test_dataset = ClassifierDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed any further, let's define a few parameters that we'll use down the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "BATCH_SIZE = 5\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "NUM_FEATURES = len(X.columns)\n",
    "NUM_CLASSES = df['Species'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now initialize our dataloaders. \n",
    "\n",
    "For `train_dataloader` we'll use `batch_size = 5` with `shuffle=True`. \n",
    "\n",
    "For `test_dataloader` we'll use `batch_size = 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Neural Net Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a simple feedforward network. \n",
    "\n",
    "`(input) 4 => 10 => 12 => 14 => 3(outupt)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulticlassClassification(nn.Module):\n",
    "    def __init__(self, num_feature, num_class):\n",
    "        super(MulticlassClassification, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(num_feature, 10)\n",
    "        self.layer_2 = nn.Linear(10, 12)\n",
    "        self.layer_3 = nn.Linear(12, 14)\n",
    "        self.layer_out = nn.Linear(14, num_class) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.lmao = None\n",
    "        \n",
    "    def access_gradients(self, grad):\n",
    "        return torch.clamp(grad, min = 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer_2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer_3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        if self.train and x.requires_grad: x.register_hook(self.access_gradients)\n",
    "  \n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MulticlassClassification(\n",
      "  (layer_1): Linear(in_features=4, out_features=10, bias=True)\n",
      "  (layer_2): Linear(in_features=10, out_features=12, bias=True)\n",
      "  (layer_3): Linear(in_features=12, out_features=14, bias=True)\n",
      "  (layer_out): Linear(in_features=14, out_features=3, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MulticlassClassification(num_feature = NUM_FEATURES, num_class=NUM_CLASSES)\n",
    "model.to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start our training, let's define a function to calculate accuracy per epoch. \n",
    "\n",
    "This function takes y_pred and y_test as input arguments. We then apply softmax to  y_pred and extract the class which has a higher probability.\n",
    "\n",
    "After that, we compare the the predicted classes and the actual classes to calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
    "    \n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    \n",
    "    acc = torch.round(acc) * 100\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5f84415b564d1fbf1fec46438a9e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: | Train Loss: 1.11018 | Train Acc: 12.500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Begin training.\")\n",
    "\n",
    "for e in tqdm(range(1, EPOCHS+1)):\n",
    "    \n",
    "    # TRAINING\n",
    "    train_epoch_loss = 0\n",
    "    train_epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "    for X_train_batch, y_train_batch in train_loader:\n",
    "        X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_train_pred = model(X_train_batch)\n",
    "        \n",
    "        train_loss = criterion(y_train_pred, y_train_batch)\n",
    "        train_acc = multi_acc(y_train_pred, y_train_batch)\n",
    "        \n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_epoch_loss += train_loss.item()\n",
    "        train_epoch_acc += train_acc.item()  \n",
    "                     \n",
    "    \n",
    "    print(f'Epoch {e+0:02}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | Train Acc: {train_epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 12])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer_3.weight.grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-bbb4d7b2df95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlmao\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
